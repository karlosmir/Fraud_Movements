{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7768d7",
   "metadata": {},
   "source": [
    "# Análisis de transacciones fraudulentas\n",
    "##  20.468 movimientos con 114 características\n",
    "\n",
    "El siguiente caso de estudio corresponde a **20.468 movimientos bancarios en los que existen transacciones fraudulentas** de modo que me dispongo a analizarlos utilizando **algoritmos de ciencia de datos para predecir si un movimiento bancario es fradulento o no**. El modelo entrenado que sea más eficiente a nivel de precisión sera el utilizado para futuros movimientos nuevos de este banco con estas características.\n",
    "\n",
    "link data: https://www.kaggle.com/datasets/volodymyrgavrysh/fraud-detection-bank-dataset-20k-records-binary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae832c0",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8b870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260852a9",
   "metadata": {},
   "source": [
    "### Clase Algoritmos\n",
    "Esta clase se encargará de calcular la precisión de los algoritmos siempre y cuando inicialice correctamente el constructor con sus parametros correctos. Después solo hay que llamar a la funcion **precision()**. También almacenará los datos de precisión en un dataframe **df** para una consulta posterior en el apartado de la conclusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a44168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {'Nombre_Algoritmo':[], 'Precision':[]}  \n",
    "df = pd.DataFrame(data=datos) \n",
    "class Algoritmos:\n",
    "    \n",
    "    def __init__(self,nombre,cm, y_test):\n",
    "        self.nombre = nombre\n",
    "        self.cm = cm\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def __str__(self):\n",
    "        return (self.nombre)\n",
    "        \n",
    "    def precision(self):\n",
    "        global df\n",
    "        assert(self.cm.shape==(2,2))\n",
    "        assert(type(self.y_test) == pd.DataFrame)\n",
    "        assert(type(self.cm[0][0]) == np.int64)\n",
    "        precision_02 = ((self.cm[0][0] + self.cm[1][1])/len(self.y_test)) * 100\n",
    "        assert(type(precision_02) == np.float64)\n",
    "        df = df.append({'Nombre_Algoritmo':self.nombre, 'Precision':precision_02}, ignore_index=True)\n",
    "        return(\"%.2f\" %precision_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa96b78",
   "metadata": {},
   "source": [
    "###  Carga y Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd5a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/USUARIO/Desktop/fraud_movents02/\"\n",
    "data = pd.read_csv(path + \"fraud_detection_bank_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba4922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>...</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>20463</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>20464</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>20465</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>20466</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20467</th>\n",
       "      <td>20467</td>\n",
       "      <td>4</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20468 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  \\\n",
       "0               0      9   1354      0     18      0      1      7      9   \n",
       "1               1      0    239      0      1      0      1      0      0   \n",
       "2               2      0    260      0      4      0      3      6      0   \n",
       "3               3     17    682      0      1      0      0      8     17   \n",
       "4               4      1    540      0      2      0      1      7      1   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "20463       20463      0     88      0      0      0      2     -1      0   \n",
       "20464       20464      0    134      0      2      0      0      6      0   \n",
       "20465       20465      4    393      1      1      0      0     -1      4   \n",
       "20466       20466      0     10      0      1      0      0     -1      0   \n",
       "20467       20467      4    399      0      3      0      1      7      4   \n",
       "\n",
       "       col_8  ...  col_103  col_104  col_105  col_106  col_107  col_108  \\\n",
       "0          0  ...        0        0        0        1        1        0   \n",
       "1          0  ...        0        1        0        0        0        0   \n",
       "2          0  ...        0        0        0        1        1        0   \n",
       "3          0  ...        0        1        0        1        1        0   \n",
       "4          0  ...        0        0        0        1        1        0   \n",
       "...      ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "20463      0  ...        0        1        0        0        0        0   \n",
       "20464      0  ...        0        0        0        0        0        0   \n",
       "20465      0  ...        0        1        0        0        0        0   \n",
       "20466      0  ...        0        0        0        0        0        0   \n",
       "20467      0  ...        0        1        0        1        1        0   \n",
       "\n",
       "       col_109  col_110  col_111  targets  \n",
       "0            0        0       49        1  \n",
       "1            0        0       55        1  \n",
       "2            0        0       56        1  \n",
       "3            0        0       65        1  \n",
       "4            0        0      175        1  \n",
       "...        ...      ...      ...      ...  \n",
       "20463        1        0       85        0  \n",
       "20464        0        0        7        0  \n",
       "20465        0        0       45        0  \n",
       "20466        0        0        5        0  \n",
       "20467        0        0       72        0  \n",
       "\n",
       "[20468 rows x 114 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba646a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5438"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizo cuantos movimimientos fraudulentos hay. \n",
    "p = data['targets'] == 1\n",
    "filtro = data[p]\n",
    "len(filtro.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb0127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>...</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "      <td>20468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10233.500000</td>\n",
       "      <td>3.226256</td>\n",
       "      <td>294.793043</td>\n",
       "      <td>0.420021</td>\n",
       "      <td>2.329343</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.939857</td>\n",
       "      <td>2.386066</td>\n",
       "      <td>3.226256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.358120</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.308384</td>\n",
       "      <td>0.190737</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.049345</td>\n",
       "      <td>0.024282</td>\n",
       "      <td>43.486125</td>\n",
       "      <td>0.265683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5908.746991</td>\n",
       "      <td>20.564308</td>\n",
       "      <td>717.541984</td>\n",
       "      <td>7.367275</td>\n",
       "      <td>10.068512</td>\n",
       "      <td>0.840537</td>\n",
       "      <td>4.222896</td>\n",
       "      <td>3.018140</td>\n",
       "      <td>20.564308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073478</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.461837</td>\n",
       "      <td>0.392892</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.216593</td>\n",
       "      <td>0.305079</td>\n",
       "      <td>59.217560</td>\n",
       "      <td>0.441707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5116.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10233.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15350.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20467.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>37808.000000</td>\n",
       "      <td>904.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         col_0         col_1         col_2         col_3  \\\n",
       "count  20468.000000  20468.000000  20468.000000  20468.000000  20468.000000   \n",
       "mean   10233.500000      3.226256    294.793043      0.420021      2.329343   \n",
       "std     5908.746991     20.564308    717.541984      7.367275     10.068512   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     5116.750000      0.000000     38.000000      0.000000      0.000000   \n",
       "50%    10233.500000      0.000000     97.000000      0.000000      1.000000   \n",
       "75%    15350.250000      2.000000    283.000000      0.000000      2.000000   \n",
       "max    20467.000000   2301.000000  37808.000000    904.000000    772.000000   \n",
       "\n",
       "              col_4         col_5         col_6         col_7    col_8  ...  \\\n",
       "count  20468.000000  20468.000000  20468.000000  20468.000000  20468.0  ...   \n",
       "mean       0.083594      0.939857      2.386066      3.226256      0.0  ...   \n",
       "std        0.840537      4.222896      3.018140     20.564308      0.0  ...   \n",
       "min        0.000000      0.000000     -1.000000      0.000000      0.0  ...   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.0  ...   \n",
       "50%        0.000000      0.000000      2.000000      0.000000      0.0  ...   \n",
       "75%        0.000000      1.000000      6.000000      2.000000      0.0  ...   \n",
       "max       54.000000    230.000000     11.000000   2301.000000      0.0  ...   \n",
       "\n",
       "            col_103       col_104       col_105       col_106       col_107  \\\n",
       "count  20468.000000  20468.000000  20468.000000  20468.000000  20468.000000   \n",
       "mean       0.004935      0.358120      0.002443      0.308384      0.190737   \n",
       "std        0.073478      0.479459      0.049366      0.461837      0.392892   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      1.000000      0.000000   \n",
       "max        2.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            col_108       col_109       col_110       col_111       targets  \n",
       "count  20468.000000  20468.000000  20468.000000  20468.000000  20468.000000  \n",
       "mean       0.000049      0.049345      0.024282     43.486125      0.265683  \n",
       "std        0.006990      0.216593      0.305079     59.217560      0.441707  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      5.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000     19.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000     61.250000      1.000000  \n",
       "max        1.000000      1.000000     17.000000    747.000000      1.000000  \n",
       "\n",
       "[8 rows x 114 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967439b",
   "metadata": {},
   "source": [
    "### Preprocesado de datos\n",
    "\n",
    "Primero compruebo si hay algun valor nulo en mi conjunto de datos. Luego observo el tipo de datos por si existiera alguna columna tipo object para transformarla. En este caso no es necesario ya que todas son entradas de datos tipo int64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102b4ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesado\n",
    "data.duplicated().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db98795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "col_0         0\n",
       "col_1         0\n",
       "col_2         0\n",
       "col_3         0\n",
       "             ..\n",
       "col_108       0\n",
       "col_109       0\n",
       "col_110       0\n",
       "col_111       0\n",
       "targets       0\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesado\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97030193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    int64\n",
       "col_0         int64\n",
       "col_1         int64\n",
       "col_2         int64\n",
       "col_3         int64\n",
       "              ...  \n",
       "col_108       int64\n",
       "col_109       int64\n",
       "col_110       int64\n",
       "col_111       int64\n",
       "targets       int64\n",
       "Length: 114, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d25ec",
   "metadata": {},
   "source": [
    "### Transformacíon de datos\n",
    "\n",
    "Almaceno las columnas que considero variables independientes y dependiente, por ejemplo en este supuesto todas las columnas son importantes en el problema menos el indice del movimiento **'unnamed:0'**. El siguiente paso es considerar quien es la variable dependiente y las variables independientes:\n",
    "\n",
    "- El objetivo de este supesto es predecir la columna **'targets'** para pronosticar si un movimiento es fraudulento  o no . De modo que la columna **'targets' será la variable dependiente**.\n",
    "\n",
    "- Todas las columnas tienen relevancia en este problema entonces **las variables independientes seran todas las columnas menos 'targets' y 'unnamed:0'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6538b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:-1]\n",
    "Y = data.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd40ab12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_102</th>\n",
       "      <th>col_103</th>\n",
       "      <th>col_104</th>\n",
       "      <th>col_105</th>\n",
       "      <th>col_106</th>\n",
       "      <th>col_107</th>\n",
       "      <th>col_108</th>\n",
       "      <th>col_109</th>\n",
       "      <th>col_110</th>\n",
       "      <th>col_111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20467</th>\n",
       "      <td>4</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20468 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "0          9   1354      0     18      0      1      7      9      0      0   \n",
       "1          0    239      0      1      0      1      0      0      0      0   \n",
       "2          0    260      0      4      0      3      6      0      0      0   \n",
       "3         17    682      0      1      0      0      8     17      0      0   \n",
       "4          1    540      0      2      0      1      7      1      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "20463      0     88      0      0      0      2     -1      0      0      0   \n",
       "20464      0    134      0      2      0      0      6      0      0      0   \n",
       "20465      4    393      1      1      0      0     -1      4      0      0   \n",
       "20466      0     10      0      1      0      0     -1      0      0      0   \n",
       "20467      4    399      0      3      0      1      7      4      0      0   \n",
       "\n",
       "       ...  col_102  col_103  col_104  col_105  col_106  col_107  col_108  \\\n",
       "0      ...        4        0        0        0        1        1        0   \n",
       "1      ...        0        0        1        0        0        0        0   \n",
       "2      ...        1        0        0        0        1        1        0   \n",
       "3      ...        1        0        1        0        1        1        0   \n",
       "4      ...        1        0        0        0        1        1        0   \n",
       "...    ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "20463  ...        0        0        1        0        0        0        0   \n",
       "20464  ...        1        0        0        0        0        0        0   \n",
       "20465  ...        0        0        1        0        0        0        0   \n",
       "20466  ...        0        0        0        0        0        0        0   \n",
       "20467  ...        1        0        1        0        1        1        0   \n",
       "\n",
       "       col_109  col_110  col_111  \n",
       "0            0        0       49  \n",
       "1            0        0       55  \n",
       "2            0        0       56  \n",
       "3            0        0       65  \n",
       "4            0        0      175  \n",
       "...        ...      ...      ...  \n",
       "20463        1        0       85  \n",
       "20464        0        0        7  \n",
       "20465        0        0       45  \n",
       "20466        0        0        5  \n",
       "20467        0        0       72  \n",
       "\n",
       "[20468 rows x 112 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544ffe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20467</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20468 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       targets\n",
       "0            1\n",
       "1            1\n",
       "2            1\n",
       "3            1\n",
       "4            1\n",
       "...        ...\n",
       "20463        0\n",
       "20464        0\n",
       "20465        0\n",
       "20466        0\n",
       "20467        0\n",
       "\n",
       "[20468 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e539a",
   "metadata": {},
   "source": [
    "### TRAIN Y TEST\n",
    "Después de visualizar los datos, preprocesarlos, considerar que columnas son relevantes para el caso de estudio y dividirlos en dos matrices ahora ya se pasaría a la fase de división de datos, es decir, considerar cuanto porcentaje de datos del dataset sería para entrenar el modelo, otro porcentaje para testearlo y verificar su precisión. Normalmente:\n",
    "\n",
    "- **TRAIN**, tiene el **80% de datos del dataset original** ya que cuanto más datos más comprobaciones realizará y más fiable será.\n",
    "- **TEST**, tiene el **20% de datos del dataset original** y con él se mide la precisión.\n",
    "\n",
    "Como sería un proceso muy laborioso hacerlo manualmente con está gran cantidad de datos hay una función en Python del modulo **sklearn** llamada **train_test_split** que nos facilita esta división de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667a6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido los datos usando la funcion train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=(0))\n",
    "\n",
    "# Escalado de variables\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# test con 4094 datos\n",
    "# train con 16.374 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50aefdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = y_test['targets'] == 1\n",
    "filtro = y_test[p]\n",
    "len(filtro.index) # Tiene 1061 movimientos fraudulentos en el test de 4094"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bd1d3",
   "metadata": {},
   "source": [
    "### Algoritmo Regresión Logística\n",
    "La regresión logística es un tipo de análisis de regresión utilizado para predecir el resultado de una variable categórica (una variable que puede adoptar un número limitado de categorías) en función de las variables independientes o predictoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e98242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2952,   81],\n",
       "       [ 394,  667]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticR = LogisticRegression(random_state=0) # random state = 0\n",
    "LogisticR.fit(X_train, y_train) #Ajustamos el modelo\n",
    "\n",
    "# Realizo la predicción de los resultados con el conjunto de testing\n",
    "y_pred = LogisticR.predict(X_test)\n",
    "\n",
    "# Matriz de confusion\n",
    "# De los 56.926 datos  entradas de clientes\n",
    "cm = confusion_matrix(y_test, y_pred) # Precisión 88.40%\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef81771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de4eb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88.40'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reg = Algoritmos(\"Regresión Logística\", cm, y_test)\n",
    "Reg.precision() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58582f",
   "metadata": {},
   "source": [
    "### Análisis discriminante lineal\n",
    "El análisis discriminante lineal (Linear Discriminant Analysis o LDA) es un método alternativo más adecuado a la regresión logística cuando la variable cualitativa tiene más de dos niveles (K ≥ 2). Supone también un modelo más estable cuando el tamaño muestral n es pequeño y la distribución de los predictores es aproximadamente normal en cada una de sus clases. El propósito del LDA es encontrar la combinación lineal de las variables originales que permita la mejor separación entre grupos de un set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ce6f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2997,   36],\n",
       "       [ 541,  520]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) # 85.91 % de precisión\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db589c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3374e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85.91'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = Algoritmos(\"Análisis discriminante lineal\", cm, y_test)\n",
    "cl.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1436ee3",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "Un clasificador AdaBoost es un metaestimador que comienza ajustando un clasificador en el conjunto de datos original y luego ajusta copias adicionales del clasificador en el mismo conjunto de datos, pero donde los pesos de las instancias clasificadas incorrectamente se ajustan de modo que los clasificadores posteriores se centren más en casos difícile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ff920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2904,  129],\n",
       "       [ 190,  871]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = AdaBoostClassifier(random_state=0)\n",
    "ad.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ad.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred) #  92.21%  de precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23efcf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bd01482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.21'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = Algoritmos(\"Análisis discriminante lineal\", cm, y_test)\n",
    "ada.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e90a9b",
   "metadata": {},
   "source": [
    "### Algoritmo KNN (K Vecinos más cercanos)\n",
    "\n",
    "Este algoritmo es un clasificador de aprendizaje supervisado no paramétrico, que utiliza la proximidad para hacer clasificaciones o predicciones sobre la agrupación de un punto de datos individual. Si bien se puede usar para problemas de regresión o clasificación, generalmente se usa como un algoritmo de clasificación, partiendo de la suposición de que se pueden encontrar puntos similares cerca uno del otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f10c8a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2868,  165],\n",
       "       [ 238,  823]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2) # Objeto clasifier\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "y_pred = KNN.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) #  90.16% de precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa8d9b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3a7fdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90.16'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = Algoritmos(\"KNV\", cm, y_test) \n",
    "KNN.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05932ea4",
   "metadata": {},
   "source": [
    "### Algoritmo Teorema de Bayes\n",
    "El teorema de Bayes es utilizado para calcular la probabilidad de un suceso, teniendo información de antemano sobre ese suceso. Podemos calcular la probabilidad de un suceso A, sabiendo además que ese A cumple cierta característica que condiciona su probabilidad. El teorema de Bayes entiende la probabilidad de forma inversa al teorema de la probabilidad total. El teorema de la probabilidad total hace inferencia sobre un suceso B, a partir de los resultados de los sucesos A. Por su parte, Bayes calcula la probabilidad de A condicionado a B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "091728aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2882,  151],\n",
       "       [ 505,  556]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BAYES = GaussianNB()\n",
    "BAYES.fit(X_train, y_train)\n",
    "\n",
    "y_pred = BAYES.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) #83.98% de precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03ff1139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb4ed2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83.98'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TeorBayes = Algoritmos(\"Teorema de Bayes\", cm, y_test)\n",
    "TeorBayes.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037bd966",
   "metadata": {},
   "source": [
    "### Árbol de Clasificación\n",
    "Un árbol de clasificación es un tipo de árbol de decisiones. Utiliza la medida de impurezas de Gini para clasificar los registros en las categorías del campo objetivo. Las predicciones se basan en combinaciones de valores en los campos de entrada.\n",
    "Un árbol de clasificación calcula la categoría de destino pronosticada para cada nodo en el árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d83616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2807,  226],\n",
       "       [ 200,  861]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = DecisionTree.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  # 89.59% de precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c847585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fa8ba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89.59'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arbol = Algoritmos(\"Árboles de Clasificación\", cm, y_test)\n",
    "Arbol.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f804960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2946,   87],\n",
       "       [ 230,  831]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aleatorio Entropia\n",
    "rand = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "rand.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) # 92.26% precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85ebf8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae1ee365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.26'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArbolRandomEntropia = Algoritmos(\"Árboles Aleatorios Entropia\", cm, y_test)\n",
    "ArbolRandomEntropia.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b564478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2948,   85],\n",
       "       [ 235,  826]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aleatorio Gini\n",
    "rand02 = RandomForestClassifier(n_estimators = 10, criterion = 'gini', random_state = 0)\n",
    "rand02.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand02.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) # 92.26% precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cd261f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e05dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.18'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArbolRandomGini = Algoritmos(\"Árboles Aleatorios Gini\", cm, y_test)\n",
    "ArbolRandomGini.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de40a8",
   "metadata": {},
   "source": [
    "### Algoritmo de XGBOOST\n",
    "XGBoost es una biblioteca de aumento de gradiente distribuida optimizada diseñada para ser altamente eficiente , flexible y portátil . Implementa algoritmos de aprendizaje automático bajo el marco Gradient Boosting . XGBoost proporciona un impulso de árbol paralelo (también conocido como GBDT, GBM) que resuelve muchos problemas de ciencia de datos de una manera rápida y precisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4de56ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2933,  100],\n",
       "       [ 146,  915]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBOOST = XGBClassifier()\n",
    "XGBOOST.fit(X_train, y_train)\n",
    "\n",
    "y_pred = XGBOOST.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred) #  93.99 % precision\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25521f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b364ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93.99'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = Algoritmos(\"XGBOOST\", cm, y_test)\n",
    "xgb.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340e8b6",
   "metadata": {},
   "source": [
    "### Algoritmo Red Neuronal Artificial\n",
    "Una red neuronal es un modelo simplificado que emula el modo en que el cerebro humano procesa la información: Funciona simultaneando un número elevado de unidades de procesamiento interconectadas que parecen versiones abstractas de neuronas.\n",
    "La red aprende examinando los registros individuales, generando una predicción para cada registro y realizando ajustes a las ponderaciones cuando realiza una predicción incorrecta. Este proceso se repite muchas veces y la red sigue mejorando sus predicciones hasta haber alcanzado uno o varios criterios de parada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "483836a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "256/256 [==============================] - 3s 4ms/step - loss: 0.7240 - accuracy: 0.3904\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.7170 - accuracy: 0.4282\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.7102 - accuracy: 0.4650\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.7035 - accuracy: 0.5005\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.5399\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6906 - accuracy: 0.5806\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6843 - accuracy: 0.6147\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6781 - accuracy: 0.6449\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6719 - accuracy: 0.6718\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6658 - accuracy: 0.6971\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6598 - accuracy: 0.7144\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6539 - accuracy: 0.7280\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6480 - accuracy: 0.7432\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6422 - accuracy: 0.7512\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.7598\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.7662\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6254 - accuracy: 0.7705\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6199 - accuracy: 0.7749\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6146 - accuracy: 0.7786\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6094 - accuracy: 0.7809\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6042 - accuracy: 0.7836\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5991 - accuracy: 0.7851\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.7868\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5894 - accuracy: 0.7886\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.7903\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5800 - accuracy: 0.7909\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7922\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5711 - accuracy: 0.7929\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5668 - accuracy: 0.7928\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5626 - accuracy: 0.7938\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5584 - accuracy: 0.7942\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5543 - accuracy: 0.7947\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5504 - accuracy: 0.7963\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5465 - accuracy: 0.7974\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5428 - accuracy: 0.7988\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5392 - accuracy: 0.7997\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5357 - accuracy: 0.8010\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.8018\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5290 - accuracy: 0.8029\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.8040\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5226 - accuracy: 0.8051\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.8060\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.8074\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.8088\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.8099\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.8112\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5050 - accuracy: 0.8121\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5023 - accuracy: 0.8134\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.8149\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4970 - accuracy: 0.8159\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4944 - accuracy: 0.8168\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4919 - accuracy: 0.8179\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.8187\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.8196\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.8203\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4823 - accuracy: 0.8211\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4799 - accuracy: 0.8223\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4777 - accuracy: 0.8229\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4754 - accuracy: 0.8234\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.8243\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.8249\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4688 - accuracy: 0.8259\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.8266\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.8273\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4627 - accuracy: 0.8280\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.8286\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4587 - accuracy: 0.8296\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8305\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4549 - accuracy: 0.8308\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.8321\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8328\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4493 - accuracy: 0.8336\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4475 - accuracy: 0.8342\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8344\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8352\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4422 - accuracy: 0.8355\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.8359\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.4388 - accuracy: 0.8362\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4372 - accuracy: 0.8366\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.8369\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4339 - accuracy: 0.8372\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.8376\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.8382\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4291 - accuracy: 0.8388\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8394\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4260 - accuracy: 0.8393\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4246 - accuracy: 0.8396\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8398\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.4216 - accuracy: 0.8402\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4202 - accuracy: 0.8405\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8411\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4174 - accuracy: 0.8416\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4160 - accuracy: 0.8418\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8425\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.8424\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4120 - accuracy: 0.8427\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.8433\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4094 - accuracy: 0.8438\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8438\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8445\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4056 - accuracy: 0.8454\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4044 - accuracy: 0.8463\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8471\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4020 - accuracy: 0.8475\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8480\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3997 - accuracy: 0.8486\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8490\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3975 - accuracy: 0.8493\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3964 - accuracy: 0.8497\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3953 - accuracy: 0.8499\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3942 - accuracy: 0.8501\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8504\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8505\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3911 - accuracy: 0.8510\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3900 - accuracy: 0.8514\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3890 - accuracy: 0.8513\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3880 - accuracy: 0.8517\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3870 - accuracy: 0.8520\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8521\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3850 - accuracy: 0.8524\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3840 - accuracy: 0.8528\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3831 - accuracy: 0.8530\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8531\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3813 - accuracy: 0.8532\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8531\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3795 - accuracy: 0.8532\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3786 - accuracy: 0.8537\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3777 - accuracy: 0.8540\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8541\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8542\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8545\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3743 - accuracy: 0.8545\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3735 - accuracy: 0.8545\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8547\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8549\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8553\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3703 - accuracy: 0.8556\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8558\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3687 - accuracy: 0.8559\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3680 - accuracy: 0.8561\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8561\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8563\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8562\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8563\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8565\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8565\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8567\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8570\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.8572\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3609 - accuracy: 0.8574\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8576\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.8576\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8579\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3582 - accuracy: 0.8579\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8579\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.8579\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3563 - accuracy: 0.8580\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8581\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.8582\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8581\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3538 - accuracy: 0.8581\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3532 - accuracy: 0.8580\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3526 - accuracy: 0.8581\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3520 - accuracy: 0.8581\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.8581\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3509 - accuracy: 0.8580\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8581\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3498 - accuracy: 0.8582\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8582\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3486 - accuracy: 0.8583\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8584\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8585\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8585\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8586\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8586\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8589\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8589\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3444 - accuracy: 0.8590\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8591\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8592\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8594\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8594\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8594\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8597\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3409 - accuracy: 0.8598\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8599\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8598\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8598\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8600\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8601\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8603\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8605\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8607\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8609\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8612\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8614\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8614\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8617\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8619\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8622\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s 3ms/step - loss: 0.6579 - accuracy: 0.6295\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5706 - accuracy: 0.8030\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5005 - accuracy: 0.8344\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4429 - accuracy: 0.8484\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8543\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.8587\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3662 - accuracy: 0.8620\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8644\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8653\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8664\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8672\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8687\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8711\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3094 - accuracy: 0.8750\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.8774\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.8804\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.8818\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.8843\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.8851\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.8854\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.8866\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.8877\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.8885\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8892\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.8897\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8905\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8909\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8920\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.8929\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8928\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8936\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8949\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.8958\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8966\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8968\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2597 - accuracy: 0.8974\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2584 - accuracy: 0.8977\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.8983\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.8987\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2545 - accuracy: 0.8994\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2532 - accuracy: 0.9004\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2520 - accuracy: 0.9008\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.9014\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2497 - accuracy: 0.9014\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2486 - accuracy: 0.9022\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9028\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2464 - accuracy: 0.9031\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9033\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.9034\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.9041\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2424 - accuracy: 0.9048\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.9044\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.9072\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.9060\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2386 - accuracy: 0.9077\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2377 - accuracy: 0.9083\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2368 - accuracy: 0.9089\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2359 - accuracy: 0.9097\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2351 - accuracy: 0.9112\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2342 - accuracy: 0.9100\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2334 - accuracy: 0.9119\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.2326 - accuracy: 0.9112\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.2318 - accuracy: 0.9121\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.2310 - accuracy: 0.9125\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2303 - accuracy: 0.9121\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2295 - accuracy: 0.9133\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2288 - accuracy: 0.9133\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2280 - accuracy: 0.9139\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2273 - accuracy: 0.9143\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2266 - accuracy: 0.9143\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2259 - accuracy: 0.9138\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.9146\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2245 - accuracy: 0.9152\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2238 - accuracy: 0.9151\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9163\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2224 - accuracy: 0.9158\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2217 - accuracy: 0.9166\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9173\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2205 - accuracy: 0.9175\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2198 - accuracy: 0.9168\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9182\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2185 - accuracy: 0.9186\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2179 - accuracy: 0.9183\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2173 - accuracy: 0.9185\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2167 - accuracy: 0.9185\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2161 - accuracy: 0.9185\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9186\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2149 - accuracy: 0.9190\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9188\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.9190\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2133 - accuracy: 0.9191\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2127 - accuracy: 0.9195\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2122 - accuracy: 0.9191\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9199\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9205\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2106 - accuracy: 0.9199\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2101 - accuracy: 0.9205\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2096 - accuracy: 0.9205\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2091 - accuracy: 0.9215\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9216\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9218\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9214\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2071 - accuracy: 0.9220\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2067 - accuracy: 0.9221\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2062 - accuracy: 0.9223\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2058 - accuracy: 0.9223\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9226\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2049 - accuracy: 0.9227\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9224\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9224\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2035 - accuracy: 0.9226\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2031 - accuracy: 0.9223\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2027 - accuracy: 0.9227\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2023 - accuracy: 0.9223\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2018 - accuracy: 0.9223\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9221\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2010 - accuracy: 0.9221\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2006 - accuracy: 0.9223\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2002 - accuracy: 0.9228\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1998 - accuracy: 0.9224\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1994 - accuracy: 0.9228\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9224\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9223\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9228\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9227\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9230\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1972 - accuracy: 0.9238\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9233\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9232\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.9235\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1958 - accuracy: 0.9242\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9240\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9239\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9243\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9240\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9246\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1938 - accuracy: 0.9245\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9249\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1931 - accuracy: 0.9249\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9247\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9248\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1922 - accuracy: 0.9251\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1919 - accuracy: 0.9249\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1916 - accuracy: 0.9252\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1913 - accuracy: 0.9251\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1910 - accuracy: 0.9256\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9255\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1904 - accuracy: 0.9254\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1901 - accuracy: 0.9256\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1898 - accuracy: 0.9258\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9261\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1893 - accuracy: 0.9258\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1890 - accuracy: 0.9258\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1887 - accuracy: 0.9257\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1885 - accuracy: 0.9262\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9262\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9262\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1877 - accuracy: 0.9262\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9261\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9267\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1869 - accuracy: 0.9267\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1866 - accuracy: 0.9264\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1864 - accuracy: 0.9265\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1861 - accuracy: 0.9266\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9268\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1857 - accuracy: 0.9267\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9268\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9271\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1850 - accuracy: 0.9273\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1847 - accuracy: 0.9269\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1845 - accuracy: 0.9268\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9268\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1840 - accuracy: 0.9271\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9272\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9271\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1834 - accuracy: 0.9272\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1832 - accuracy: 0.9273\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1829 - accuracy: 0.9272\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9274\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9271\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9273\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1821 - accuracy: 0.9276\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1819 - accuracy: 0.9274\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1817 - accuracy: 0.9274\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1815 - accuracy: 0.9274\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9268\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.9274\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9275\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9279\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9276\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9279\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9278\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9280\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1798 - accuracy: 0.9281\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1796 - accuracy: 0.9281\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1794 - accuracy: 0.9281\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1792 - accuracy: 0.9281\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1790 - accuracy: 0.9283\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9284\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1786 - accuracy: 0.9284\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8609\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.9135\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1977 - accuracy: 0.9218\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1850 - accuracy: 0.9267\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9306\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9336\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9342\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9397\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9364\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1503 - accuracy: 0.9396\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9414\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1387 - accuracy: 0.9446\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9455\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9463\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9483\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1264 - accuracy: 0.9486\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1243 - accuracy: 0.9502\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9508\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1207 - accuracy: 0.9530\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9547\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9554\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9539\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9551\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9561\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9579\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9577\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1052 - accuracy: 0.9582\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9617\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9605\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9613\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9628\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9586\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9620\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9625\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9626\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9631\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9591\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9637\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9649\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9650\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9660\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9664\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9653\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9671\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9642\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0804 - accuracy: 0.9662\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9682\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0855 - accuracy: 0.9659\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9658\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9652\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9687\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9673\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9678\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9688\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0771 - accuracy: 0.9682\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0753 - accuracy: 0.9693\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9696\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9700\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9692\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9714\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9702\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9688\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9672\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9684\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9714\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.9733\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.9723\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9727\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9726\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9673\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9679\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9714\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9740\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9745\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9736\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9722\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9736\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9732\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9739\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0612 - accuracy: 0.9753\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 0.9743\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9734\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0771 - accuracy: 0.9706\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.9712\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0693 - accuracy: 0.9726\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9732\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9765\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9750\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9761\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9755\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9753\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9749\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9716\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9720\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9720\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9751\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9765\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9758\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9771\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9786\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9776\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9775\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9770\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 0.9756\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9772\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9758\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9757\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 0.9759\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9760\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0560 - accuracy: 0.9763\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9790\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9774\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 0.9757\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9748\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0574 - accuracy: 0.9769\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0542 - accuracy: 0.9783\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0521 - accuracy: 0.9784\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0543 - accuracy: 0.9776\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0521 - accuracy: 0.9777\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 2s 8ms/step - loss: 0.0502 - accuracy: 0.9801\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0557 - accuracy: 0.9781\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0562 - accuracy: 0.9770\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9785\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9801\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.9787\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9795\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9785\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0545 - accuracy: 0.9789\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9795\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9798\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9779\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9751\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9786\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9808\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9811\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9784\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9781\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9791\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9808\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.9809\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9813\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9816\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9813\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9791\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9809\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0539 - accuracy: 0.9775\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9809\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9788\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9791\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0511 - accuracy: 0.9794\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0504 - accuracy: 0.9802\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9776\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0482 - accuracy: 0.9811\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0514 - accuracy: 0.9797\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9805\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9818\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9815\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0449 - accuracy: 0.9807\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9819\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9827\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9797\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9808\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9816\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9778\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9773\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9788\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9806\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9823\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9834\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9838\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9836\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9807\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9826\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9810\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9833\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9794\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9807\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9820\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9820\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9830\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9823\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0431 - accuracy: 0.9817\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9826\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9807\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9809\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9818\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0400 - accuracy: 0.9838\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0423 - accuracy: 0.9822\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9831\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9833\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9817\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.9821\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9826\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9825\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9812\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9793\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9827\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9842\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9832\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9838\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s 3ms/step - loss: 0.3683 - accuracy: 0.8445\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.8943\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2319 - accuracy: 0.9090\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.9152\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9205\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1924 - accuracy: 0.9223\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9260\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9270\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1765 - accuracy: 0.9285\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1717 - accuracy: 0.9309\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9324\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9336\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9351\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1587 - accuracy: 0.9372\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9378\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9378\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9394\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1484 - accuracy: 0.9389\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1456 - accuracy: 0.9420\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9410\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9428\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9436\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9445\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1331 - accuracy: 0.9461\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9455\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1310 - accuracy: 0.9471\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1302 - accuracy: 0.9468\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1255 - accuracy: 0.9494\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1244 - accuracy: 0.9496\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1247 - accuracy: 0.9490\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1206 - accuracy: 0.9510\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9528\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9534\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9534\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9543\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9553\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9560\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1101 - accuracy: 0.9571\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1081 - accuracy: 0.9570\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9575\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9582\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9588\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9590\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9580\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9609\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9604\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9596\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9616\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9617\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9616\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9619\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9633\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9634\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9638\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9634\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9648\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9638\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9650\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9661\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9640\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9654\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.9660\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9667\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9652\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9665\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9673\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9684\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9675\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9679\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9680\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.9685\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9690\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0787 - accuracy: 0.9697\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0776 - accuracy: 0.9687\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9712\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9703\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9698\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9701\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.9684\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0754 - accuracy: 0.9695\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9699\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0763 - accuracy: 0.9687\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9696\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0727 - accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9720\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9712\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9712\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9699\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.9734\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9729\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9720\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9722\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9717\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9728\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0694 - accuracy: 0.9726\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9738\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9728\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9728\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9735\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9733\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9731\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.9739\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9726\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9737\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9740\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9745\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9747\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9742\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9733\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9735\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0640 - accuracy: 0.9747\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9742\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9758\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9737\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9754\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9761\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9749\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9760\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9745\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9758\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0627 - accuracy: 0.9744\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9748\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9759\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9747\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9753\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0627 - accuracy: 0.9750\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9751\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9745\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9757\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9747\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9761\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9762\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0611 - accuracy: 0.9751\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0628 - accuracy: 0.9744\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9746\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9759\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9768\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 0.9752\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9762\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9765\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9765\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9760\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0581 - accuracy: 0.9767\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9740\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9765\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9768\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9780\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9770\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.9777\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9781\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9778\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9770\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9778\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9762\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9781\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9778\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9764\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9767\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0577 - accuracy: 0.9762\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9789\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9780\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9783\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9779\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0553 - accuracy: 0.9767\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9783\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9773\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9775\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.9774\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9767\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9780\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9776\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9768\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.9783\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9781\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9788\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9787\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9780\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9785\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9784\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9775\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9781\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9791\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9792\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9786\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9783\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9786\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9795\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9800\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9783\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9789\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9787\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9781\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9794\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9801\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9790\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9783\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9796\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9799\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9800\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s 3ms/step - loss: 0.6892 - accuracy: 0.7327\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.7327\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6828 - accuracy: 0.7327\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6808 - accuracy: 0.7327\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6791 - accuracy: 0.7327\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6776 - accuracy: 0.7327\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6761 - accuracy: 0.7327\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.7327\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6736 - accuracy: 0.7327\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6724 - accuracy: 0.7327\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6712 - accuracy: 0.7327\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6701 - accuracy: 0.7327\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6690 - accuracy: 0.7327\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6679 - accuracy: 0.7327\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7327\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6657 - accuracy: 0.7327\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6646 - accuracy: 0.7327\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6636 - accuracy: 0.7327\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6625 - accuracy: 0.7327\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.7327\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.7327\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6593 - accuracy: 0.7327\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6583 - accuracy: 0.7327\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6572 - accuracy: 0.7327\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6562 - accuracy: 0.7327\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6552 - accuracy: 0.7327\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6542 - accuracy: 0.7327\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6531 - accuracy: 0.7327\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6521 - accuracy: 0.7327\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6511 - accuracy: 0.7327\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6501 - accuracy: 0.7327\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6491 - accuracy: 0.7327\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6481 - accuracy: 0.7327\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6470 - accuracy: 0.7327\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6460 - accuracy: 0.7327\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6450 - accuracy: 0.7327\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6439 - accuracy: 0.7327\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.7327\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6417 - accuracy: 0.7327\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6406 - accuracy: 0.7327\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6395 - accuracy: 0.7327\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6384 - accuracy: 0.7327\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6372 - accuracy: 0.7327\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6361 - accuracy: 0.7327\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.7327\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.7327\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6326 - accuracy: 0.7327\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6314 - accuracy: 0.7327\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6302 - accuracy: 0.7327\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.7327\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6279 - accuracy: 0.7327\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6268 - accuracy: 0.7327\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.7327\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.7327\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6234 - accuracy: 0.7327\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6223 - accuracy: 0.7327\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.7327\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6202 - accuracy: 0.7327\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.7327\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.7327\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6171 - accuracy: 0.7327\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6160 - accuracy: 0.7327\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.7327\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6141 - accuracy: 0.7327\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6131 - accuracy: 0.7327\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6121 - accuracy: 0.7327\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6112 - accuracy: 0.7327\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.6103 - accuracy: 0.7327\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6094 - accuracy: 0.7327\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.6085 - accuracy: 0.7327\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.6077 - accuracy: 0.7327\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6068 - accuracy: 0.7327\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6060 - accuracy: 0.7327\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6052 - accuracy: 0.7327\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.6044 - accuracy: 0.7327\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6036 - accuracy: 0.7327\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.7327\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.6022 - accuracy: 0.7327\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.6015 - accuracy: 0.7327\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.6008 - accuracy: 0.7327\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.7327\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5994 - accuracy: 0.7327\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5988 - accuracy: 0.7327\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5981 - accuracy: 0.7327\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5975 - accuracy: 0.7327\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.7327\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5964 - accuracy: 0.7327\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5958 - accuracy: 0.7327\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.7327\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.7327\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.7327\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.7327\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5932 - accuracy: 0.7327\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7327\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.7327\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5918 - accuracy: 0.7327\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.7327\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5910 - accuracy: 0.7327\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.7327\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5901 - accuracy: 0.7327\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5898 - accuracy: 0.7327\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5894 - accuracy: 0.7327\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.7327\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5887 - accuracy: 0.7327\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5884 - accuracy: 0.7327\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.7327\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.7327\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5874 - accuracy: 0.7327\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5871 - accuracy: 0.7327\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5868 - accuracy: 0.7327\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5866 - accuracy: 0.7327\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5863 - accuracy: 0.7327\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5861 - accuracy: 0.7327\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5858 - accuracy: 0.7327\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.7327\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5854 - accuracy: 0.7327\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5851 - accuracy: 0.7327\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5849 - accuracy: 0.7327\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5847 - accuracy: 0.7327\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.7327\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5844 - accuracy: 0.7327\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5842 - accuracy: 0.7327\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5840 - accuracy: 0.7327\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5839 - accuracy: 0.7327\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5837 - accuracy: 0.7327\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5836 - accuracy: 0.7327\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.7327\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5833 - accuracy: 0.7327\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5832 - accuracy: 0.7327\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5830 - accuracy: 0.7327\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5829 - accuracy: 0.7327\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5828 - accuracy: 0.7327\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5827 - accuracy: 0.7327\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5826 - accuracy: 0.7327\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.7327\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5824 - accuracy: 0.7327\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5823 - accuracy: 0.7327\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5822 - accuracy: 0.7327\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5821 - accuracy: 0.7327\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5821 - accuracy: 0.7327\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5820 - accuracy: 0.7327\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5819 - accuracy: 0.7327\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5818 - accuracy: 0.7327\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5818 - accuracy: 0.7327\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5817 - accuracy: 0.7327\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.7327\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5816 - accuracy: 0.7327\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.7327\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5815 - accuracy: 0.7327\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5815 - accuracy: 0.7327\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5814 - accuracy: 0.7327\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5814 - accuracy: 0.7327\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.7327\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.7327\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5813 - accuracy: 0.7327\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5812 - accuracy: 0.7327\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5812 - accuracy: 0.7327\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5812 - accuracy: 0.7327\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5811 - accuracy: 0.7327\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5811 - accuracy: 0.7327\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5811 - accuracy: 0.7327\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.7327\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.7327\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.7327\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.7327\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5810 - accuracy: 0.7327\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5809 - accuracy: 0.7327\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5808 - accuracy: 0.7327\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.7327\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5806 - accuracy: 0.7327\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7327\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7327\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.5806 - accuracy: 0.7327\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 3s 3ms/step - loss: 0.3196 - accuracy: 0.8721\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9165\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9246\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1767 - accuracy: 0.9299\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9329\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1640 - accuracy: 0.9355\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1567 - accuracy: 0.9366\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.9391\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9423\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9419\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1411 - accuracy: 0.9435\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1345 - accuracy: 0.9475\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9472\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9484\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9503\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1208 - accuracy: 0.9511\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1174 - accuracy: 0.9525\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9542\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9552\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9559\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1062 - accuracy: 0.9572\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9568\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9557\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9583\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9596\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9596\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9608\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9613\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1113 - accuracy: 0.9613\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9623\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9623\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9630\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0869 - accuracy: 0.9643\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9653\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9667\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9666\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9659\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9668\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9640\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9662\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0822 - accuracy: 0.9667\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9665\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9659\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9664\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9687\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9701\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9685\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9688\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9700\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9690\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0720 - accuracy: 0.9701\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0713 - accuracy: 0.9701\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9706\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9696\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9696\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0791 - accuracy: 0.9688\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9704\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9717\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9715\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9701\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9674\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9681\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9705\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9726\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9743\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9742\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0640 - accuracy: 0.9737\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9735\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0650 - accuracy: 0.9731\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9733\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9740\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9703\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0874 - accuracy: 0.9675\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9728\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 0.9745\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9747\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9747\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9743\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 0.9751\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9747\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9737\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9744\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9749\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9755\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9756\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9745\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9681\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9707\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9751\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9759\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9756\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9773\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9765\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9771\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9763\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9755\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9768\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9781\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9731\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9710\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9761\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9780\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9776\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 0.9782\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0517 - accuracy: 0.9782\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9784\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9759\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9714\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9742\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0548 - accuracy: 0.9765\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0501 - accuracy: 0.9800\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9786\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9794\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9789\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9787\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9791\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9774\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9750\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9775\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9776\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9798\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0493 - accuracy: 0.9800\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0657 - accuracy: 0.9758\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0577 - accuracy: 0.9759\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9788\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9798\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9765\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9776\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9792\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9794\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0485 - accuracy: 0.9802\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9806\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0481 - accuracy: 0.9801\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9794\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9794\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9775\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9779\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9790\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0523 - accuracy: 0.9792\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0530 - accuracy: 0.9796\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9803\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9809\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9806\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9808\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9792\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9789\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9803\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9791\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9777\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9799\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9802\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9817\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9813\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9791\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9810\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9815\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9815\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0427 - accuracy: 0.9824\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0429 - accuracy: 0.9816\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9822\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9822\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0444 - accuracy: 0.9813\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0569 - accuracy: 0.9781\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9778\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9785\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9813\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0405 - accuracy: 0.9836\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9834\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9827\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9819\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0449 - accuracy: 0.9813\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9822\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9826\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9823\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9806\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9809\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9792\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9792\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9809\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9817\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9833\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9824\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0420 - accuracy: 0.9824\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0422 - accuracy: 0.9820\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9817\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0483 - accuracy: 0.9833\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9831\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9828\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9817\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9826\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9828\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0502 - accuracy: 0.9811\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0452 - accuracy: 0.9820\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0387 - accuracy: 0.9842\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9831\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9816\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0473 - accuracy: 0.9814\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0476 - accuracy: 0.9814\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9830\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9831\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 3s 4ms/step - loss: 0.3096 - accuracy: 0.8780\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2213 - accuracy: 0.9150\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9203\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1907 - accuracy: 0.9246\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9270\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1769 - accuracy: 0.9312\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1692 - accuracy: 0.9334\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9359\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.9382\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9390\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1474 - accuracy: 0.9422\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9431\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9451\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9453\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9491\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1266 - accuracy: 0.9498\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9488\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1224 - accuracy: 0.9511\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9527\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9555\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9553\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1186 - accuracy: 0.9567\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9582\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9583\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9583\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9598\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9593\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9613\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9623\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9629\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9628\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9627\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9629\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9640\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9642\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9652\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9656\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9652\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9676\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9660\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9668\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9678\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9675\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9692\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9680\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.9688\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9692\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9695\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9694\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9691\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9686\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9687\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9697\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9703\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9707\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9703\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.9708\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0739 - accuracy: 0.9724\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9710\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9719\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9722\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9718\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9722\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0717 - accuracy: 0.9722\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9728\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9723\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9723\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.9725\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0742 - accuracy: 0.9732\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9736\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0673 - accuracy: 0.9742\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9739\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9742\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9746\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9722\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9744\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9730\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9745\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9738\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9754\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9753\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9751\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9758\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9754\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9750\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9744\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9759\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0693 - accuracy: 0.9745\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9745\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9761\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9753\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9764\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9766\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9779\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9759\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9756\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9755\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9759\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9775\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9762\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9765\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9775\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0595 - accuracy: 0.9773\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.9764\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9768\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9775\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9773\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9775\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9759\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9783\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9777\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9775\n",
      "Epoch 114/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.9776\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0627 - accuracy: 0.9772\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0597 - accuracy: 0.9783\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0572 - accuracy: 0.9779\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9780\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0598 - accuracy: 0.9783\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9779\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9792\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0864 - accuracy: 0.9789\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.0906 - accuracy: 0.9790\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0553 - accuracy: 0.9792\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9785\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9776\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9789\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9786\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9797\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9798\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9807\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9797\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9786\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9800\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9789\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9795\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9792\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9794\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9802\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0523 - accuracy: 0.9798\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0531 - accuracy: 0.9798\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0680 - accuracy: 0.9792\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9800\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9795\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9794\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9800\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9807\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9798\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9795\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9796\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9791\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9809\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9806\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9806\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9806\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9799\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9811\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9796\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9809\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9795\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9801\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9805\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9805\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9814\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9808\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9813\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9802\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0539 - accuracy: 0.9808\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.0550 - accuracy: 0.9817\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0541 - accuracy: 0.9808\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9802\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9799\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9805\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9803\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9802\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9811\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9810\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9811\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9808\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9807\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9819\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9818\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9811\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9813\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9809\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9819\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9820\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9816\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9824\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9814\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.9814\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9810\n",
      "Epoch 193/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0670 - accuracy: 0.9822\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9816\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9821\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.9815\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9805\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9819\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9822\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9814\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s 3ms/step - loss: 0.5905 - accuracy: 0.7198\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8412\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.8600\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.3134 - accuracy: 0.8670\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.8795\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.8859\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8907\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.8958\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.9026\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2376 - accuracy: 0.9079\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2292 - accuracy: 0.9112\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2213 - accuracy: 0.9145\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2145 - accuracy: 0.9196\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9200\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2017 - accuracy: 0.9214\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9227\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1929 - accuracy: 0.9249\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1887 - accuracy: 0.9271\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1855 - accuracy: 0.9264\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1821 - accuracy: 0.9284\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9287\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9292\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1782 - accuracy: 0.9299\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9324\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1724 - accuracy: 0.9321\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 0.9332\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9347\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9350\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1629 - accuracy: 0.9353\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9378\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9366\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9385\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1564 - accuracy: 0.9389\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1550 - accuracy: 0.9398\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1529 - accuracy: 0.9400\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9401\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9414\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1505 - accuracy: 0.9404\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9409\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1483 - accuracy: 0.9417\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1494 - accuracy: 0.9422\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9434\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1465 - accuracy: 0.9448\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1428 - accuracy: 0.9429\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1416 - accuracy: 0.9442\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1400 - accuracy: 0.9443\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9455\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1372 - accuracy: 0.9461\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1373 - accuracy: 0.9458\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9477\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9474\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9475\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1359 - accuracy: 0.9479\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9483\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9489\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1301 - accuracy: 0.9493\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9502\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1289 - accuracy: 0.9493\n",
      "Epoch 60/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9502\n",
      "Epoch 61/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1269 - accuracy: 0.9496\n",
      "Epoch 62/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9508\n",
      "Epoch 63/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1248 - accuracy: 0.9524\n",
      "Epoch 64/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1234 - accuracy: 0.9518\n",
      "Epoch 65/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1232 - accuracy: 0.9518\n",
      "Epoch 66/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9532\n",
      "Epoch 67/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1226 - accuracy: 0.9512\n",
      "Epoch 68/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9541\n",
      "Epoch 69/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1216 - accuracy: 0.9527\n",
      "Epoch 70/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1206 - accuracy: 0.9532\n",
      "Epoch 71/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9548\n",
      "Epoch 72/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9547\n",
      "Epoch 73/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9557\n",
      "Epoch 74/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1162 - accuracy: 0.9551\n",
      "Epoch 75/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1153 - accuracy: 0.9551\n",
      "Epoch 76/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9561\n",
      "Epoch 77/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9560\n",
      "Epoch 78/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9563\n",
      "Epoch 79/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9551\n",
      "Epoch 80/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9565\n",
      "Epoch 81/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9573\n",
      "Epoch 82/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1116 - accuracy: 0.9571\n",
      "Epoch 83/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9582\n",
      "Epoch 84/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1106 - accuracy: 0.9574\n",
      "Epoch 85/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9576\n",
      "Epoch 86/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9583\n",
      "Epoch 87/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9593\n",
      "Epoch 88/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9599\n",
      "Epoch 89/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9592\n",
      "Epoch 90/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9585\n",
      "Epoch 91/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1057 - accuracy: 0.9605\n",
      "Epoch 92/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9599\n",
      "Epoch 93/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9607\n",
      "Epoch 94/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9598\n",
      "Epoch 95/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9598\n",
      "Epoch 96/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9610\n",
      "Epoch 97/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1032 - accuracy: 0.9614\n",
      "Epoch 98/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9610\n",
      "Epoch 99/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9616\n",
      "Epoch 100/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9611\n",
      "Epoch 101/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1019 - accuracy: 0.9596\n",
      "Epoch 102/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9615\n",
      "Epoch 103/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1025 - accuracy: 0.9616\n",
      "Epoch 104/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9609\n",
      "Epoch 105/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9612\n",
      "Epoch 106/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9616\n",
      "Epoch 107/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9620\n",
      "Epoch 108/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9626\n",
      "Epoch 109/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1019 - accuracy: 0.9607\n",
      "Epoch 110/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0998 - accuracy: 0.9627\n",
      "Epoch 111/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0958 - accuracy: 0.9627\n",
      "Epoch 112/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9621\n",
      "Epoch 113/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9637\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9634\n",
      "Epoch 115/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9628\n",
      "Epoch 116/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9631\n",
      "Epoch 117/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9628\n",
      "Epoch 118/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9639\n",
      "Epoch 119/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9638\n",
      "Epoch 120/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9638\n",
      "Epoch 121/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9651\n",
      "Epoch 122/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9639\n",
      "Epoch 123/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0920 - accuracy: 0.9637\n",
      "Epoch 124/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9648\n",
      "Epoch 125/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0917 - accuracy: 0.9646\n",
      "Epoch 126/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9653\n",
      "Epoch 127/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9665\n",
      "Epoch 128/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9648\n",
      "Epoch 129/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9650\n",
      "Epoch 130/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9664\n",
      "Epoch 131/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9667\n",
      "Epoch 132/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9659\n",
      "Epoch 133/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9656\n",
      "Epoch 134/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9654\n",
      "Epoch 135/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9656\n",
      "Epoch 136/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9663\n",
      "Epoch 137/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9666\n",
      "Epoch 138/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9671\n",
      "Epoch 139/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9662\n",
      "Epoch 140/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9671\n",
      "Epoch 141/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9665\n",
      "Epoch 142/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9668\n",
      "Epoch 143/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9676\n",
      "Epoch 144/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9674\n",
      "Epoch 145/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9676\n",
      "Epoch 146/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9678\n",
      "Epoch 147/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9681\n",
      "Epoch 148/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9669\n",
      "Epoch 149/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9667\n",
      "Epoch 150/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9668\n",
      "Epoch 151/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9675\n",
      "Epoch 152/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9690\n",
      "Epoch 153/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9690\n",
      "Epoch 154/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9682\n",
      "Epoch 155/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9680\n",
      "Epoch 156/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9685\n",
      "Epoch 157/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9685\n",
      "Epoch 158/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9678\n",
      "Epoch 159/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9684\n",
      "Epoch 160/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9688\n",
      "Epoch 161/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9683\n",
      "Epoch 162/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9685\n",
      "Epoch 163/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9681\n",
      "Epoch 164/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9696\n",
      "Epoch 165/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9691\n",
      "Epoch 166/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9672\n",
      "Epoch 167/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9698\n",
      "Epoch 168/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9679\n",
      "Epoch 169/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9685\n",
      "Epoch 170/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9698\n",
      "Epoch 171/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9695\n",
      "Epoch 172/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9670\n",
      "Epoch 173/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9689\n",
      "Epoch 174/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9693\n",
      "Epoch 175/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9678\n",
      "Epoch 176/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9651\n",
      "Epoch 177/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9688\n",
      "Epoch 178/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9685\n",
      "Epoch 179/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9698\n",
      "Epoch 180/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9693\n",
      "Epoch 181/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9693\n",
      "Epoch 182/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9696\n",
      "Epoch 183/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9700\n",
      "Epoch 184/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9711\n",
      "Epoch 185/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9705\n",
      "Epoch 186/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9711\n",
      "Epoch 187/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9706\n",
      "Epoch 188/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9696\n",
      "Epoch 189/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9698\n",
      "Epoch 190/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9717\n",
      "Epoch 191/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9708\n",
      "Epoch 192/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9710\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9692\n",
      "Epoch 194/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0750 - accuracy: 0.9693\n",
      "Epoch 195/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9706\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.0726 - accuracy: 0.9710\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 1s 5ms/step - loss: 0.0744 - accuracy: 0.9704\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9703\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9715\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0742 - accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "# red neuronal artificial con keras del modelo secuencial\n",
    "diccionario = {0:'Adadelta',1:'Adagrad',2:'Adam',3:'Adamax',4:'Ftrl',5:'Nadam',6:'RMSprop',7:'SGD'}\n",
    "for optimi in diccionario.values():\n",
    "    RNA = tf.keras.models.Sequential()\n",
    "    # 1Âº Capa de inputs\n",
    "    RNA.add(tf.keras.layers.Dense(units=114, activation='relu'))\n",
    "    # 2Âº Capa oculta\n",
    "    RNA.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "    # Capa oculta\n",
    "    RNA.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
    "    #  Capa Capa oculta\n",
    "    RNA.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "    # Ultima capa de salidad, con funcion sigmoide\n",
    "    RNA.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    RNA.compile(optimizer = optimi, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    RNA.fit(X_train, y_train, batch_size = 64, epochs = 200)\n",
    "    \n",
    "    y_pred = RNA.predict(X_test)\n",
    "    y_pred_02 = (y_pred > 0.5)\n",
    "    y_pred_02 = np.where(y_pred_02=='True',1,y_pred_02)\n",
    "    cm = confusion_matrix(y_test, y_pred_02)    \n",
    "    redneuro = Algoritmos(\"Red Neuronal Artificial Optimizador: \" + str(optimi), cm, y_test)\n",
    "    redneuro.precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97013266",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec76024",
   "metadata": {},
   "source": [
    "Después de testear y ajustar los datos con **16 modelos distintos de algoritmos**, **la mejor precisión** la realiza el algoritmo de **Xgboost** con un **93.99 %**.\n",
    "\n",
    "Si observo su matriz de confusión del testing se pueder ver que:\n",
    "- ([[2933,  100],[ 146,  915]], de los **4094 movimientos ha acertado correctamente 915 transacciones fraudulentas y 2933 transacciones no fraudulentas**.\n",
    "\n",
    "Este modelo sería muy eficaz para pronosticar cualquier otra transaccion fraudulenta con estas mismas características en este banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f26c434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre_Algoritmo</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>93.991207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Árboles Aleatorios Entropia</td>\n",
       "      <td>92.256961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Análisis discriminante lineal</td>\n",
       "      <td>92.208109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Árboles Aleatorios Gini</td>\n",
       "      <td>92.183683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Adagrad</td>\n",
       "      <td>91.744016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Adamax</td>\n",
       "      <td>91.157792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Nadam</td>\n",
       "      <td>91.108940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Adam</td>\n",
       "      <td>90.962384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: RMSprop</td>\n",
       "      <td>90.522716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNV</td>\n",
       "      <td>90.156326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: SGD</td>\n",
       "      <td>89.692233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Árboles de Clasificación</td>\n",
       "      <td>89.594529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresión Logística</td>\n",
       "      <td>88.397655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Adadelta</td>\n",
       "      <td>86.248168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Análisis discriminante lineal</td>\n",
       "      <td>85.906204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teorema de Bayes</td>\n",
       "      <td>83.976551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Red Neuronal Artificial Optimizador: Ftrl</td>\n",
       "      <td>74.084025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nombre_Algoritmo  Precision\n",
       "8                                         XGBOOST  93.991207\n",
       "6                     Árboles Aleatorios Entropia  92.256961\n",
       "2                   Análisis discriminante lineal  92.208109\n",
       "7                         Árboles Aleatorios Gini  92.183683\n",
       "10   Red Neuronal Artificial Optimizador: Adagrad  91.744016\n",
       "12    Red Neuronal Artificial Optimizador: Adamax  91.157792\n",
       "14     Red Neuronal Artificial Optimizador: Nadam  91.108940\n",
       "11      Red Neuronal Artificial Optimizador: Adam  90.962384\n",
       "15   Red Neuronal Artificial Optimizador: RMSprop  90.522716\n",
       "3                                             KNV  90.156326\n",
       "16       Red Neuronal Artificial Optimizador: SGD  89.692233\n",
       "5                        Árboles de Clasificación  89.594529\n",
       "0                             Regresión Logística  88.397655\n",
       "9   Red Neuronal Artificial Optimizador: Adadelta  86.248168\n",
       "1                   Análisis discriminante lineal  85.906204\n",
       "4                                Teorema de Bayes  83.976551\n",
       "13      Red Neuronal Artificial Optimizador: Ftrl  74.084025"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Precision',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e5ad5",
   "metadata": {},
   "source": [
    "Si quisiera saber que **importancia le ha dado a las columnas/características** haciendo las clasificaciones para determinar si un transacción es fraudulenta o no, a continuación lo muestro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8136c5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Importancia %\n",
      "83       23.584557\n",
      "5        12.259048\n",
      "106      11.187807\n",
      "54        4.734734\n",
      "74        2.916551\n",
      "4         2.846203\n",
      "26        2.453791\n",
      "102       2.006691\n",
      "76        1.680843\n",
      "95        1.438495\n"
     ]
    }
   ],
   "source": [
    "# Voy a ver que columnas le ha dado mas importancia para el modelo\n",
    "col_imp = XGBOOST.feature_importances_\n",
    "col_name = XGBOOST.get_booster().feature_names\n",
    "dataXgboost = pd.DataFrame(col_imp, col_name)\n",
    "dataXgboost = dataXgboost.rename(columns={0:'Importancia %'})\n",
    "orden_desce = dataXgboost.sort_values('Importancia %',ascending=False)\n",
    "orden_desce = orden_desce.iloc[:] * 100\n",
    "print(orden_desce.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91f638",
   "metadata": {},
   "source": [
    "En resumen, el algoritmo **XGBOOST con una precisión de casi 94%** ha tomado con mayor peso estadístico para predecir si un movimiento es fraudulento o no las columnas/características:\n",
    "\n",
    "|**Columna**|**Importancia %**|\n",
    "|------|------|\n",
    "|83  |23.584557  |\n",
    "|5  |12.259048  |\n",
    "|106  |11.187807  |\n",
    "|54  |4.734734  |\n",
    "|74  |2.916551  |\n",
    "|4  |2.846203  |\n",
    "|26  |2.453791  |\n",
    "|102  |2.006691  |\n",
    "|76  |1.680843  |\n",
    "|95  |1.438495  |\n",
    "\n",
    "\n",
    "**Siendo las características 83, 5 y 106 muy determinantes.** Esto es muy útil si queremos que el banco realice a priori ciertos \"controles/filtros\" a sus clientes respecto a estas características, de modo que lo que podría ser realmente eficiente sería poner una alerta si el cliente realiza un movimiento y hay una alta desviación en estas 3 columnas junto con el modelo de Xgboost que te predice si una transacción es fraudulenta o no.\n",
    "\n",
    "\n",
    "**Autor: Carlos Mir Martínez**\n",
    "\n",
    "**Fecha: 22/06/2022**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
